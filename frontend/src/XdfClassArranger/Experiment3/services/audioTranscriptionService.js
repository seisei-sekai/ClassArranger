/**
 * Audio Transcription Service
 * éŸ³é¢‘è½¬å†™æœåŠ¡
 *
 * Handles audio file upload and transcription using OpenAI Whisper API
 * ä½¿ç”¨OpenAI Whisper APIå¤„ç†éŸ³é¢‘æ–‡ä»¶ä¸Šä¼ å’Œè½¬å†™
 */

class AudioTranscriptionService {
  constructor() {
    const apiUrl = import.meta.env.VITE_API_URL || "http://localhost:8000";
    this.baseURL = `${apiUrl}/ai/whisper/transcribe`;

    // Get auth token from localStorage (use same key as AuthContext)
    this.getAuthToken = () => {
      return localStorage.getItem("auth_token");
    };

    console.log("âœ… Audio Transcription Service initialized");
    console.log(`ğŸ“¡ Backend endpoint: ${this.baseURL}`);
  }

  /**
   * Transcribe audio file
   * è½¬å†™éŸ³é¢‘æ–‡ä»¶
   *
   * @param {File} audioFile - Audio file to transcribe
   * @param {Function} onProgress - Progress callback (0-100)
   * @returns {Promise<Object>} Transcription result
   */
  async transcribeAudio(audioFile, onProgress) {
    // Validate file
    if (!audioFile) {
      throw new Error("è¯·é€‰æ‹©éŸ³é¢‘æ–‡ä»¶");
    }

    // Validate file type
    const allowedTypes = [
      "audio/mpeg",
      "audio/mp3",
      "audio/mp4",
      "audio/wav",
      "audio/webm",
    ];
    const allowedExtensions = [
      ".mp3",
      ".mp4",
      ".mpeg",
      ".mpga",
      ".m4a",
      ".wav",
      ".webm",
    ];

    const fileExt = "." + audioFile.name.split(".").pop().toLowerCase();

    if (
      !allowedTypes.includes(audioFile.type) &&
      !allowedExtensions.includes(fileExt)
    ) {
      throw new Error(
        `ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ã€‚æ”¯æŒçš„æ ¼å¼: ${allowedExtensions.join(", ")}`,
      );
    }

    // Validate file size (100MB limit with auto-segmentation)
    const maxSize = 100 * 1024 * 1024; // 100MB
    if (audioFile.size > maxSize) {
      throw new Error(
        `æ–‡ä»¶å¤§å°ä¸èƒ½è¶…è¿‡100MB (å½“å‰: ${(audioFile.size / 1024 / 1024).toFixed(2)}MB)`,
      );
    }

    // Create form data
    const formData = new FormData();
    formData.append("file", audioFile);

    try {
      // Get auth token
      const token = this.getAuthToken();
      if (!token) {
        throw new Error("æœªç™»å½•ï¼Œè¯·å…ˆç™»å½•");
      }

      // Upload starts - set to 10%
      if (onProgress) onProgress(10);

      // Make request with XMLHttpRequest for progress tracking
      const result = await this.uploadWithProgress(formData, token, onProgress);

      return result;
    } catch (error) {
      console.error("Transcription error:", error);

      // Handle different error types
      if (error.response) {
        const detail = error.response.data?.detail;
        if (typeof detail === "string") {
          throw new Error(detail);
        } else if (detail?.message) {
          throw new Error(detail.message);
        }
      }

      throw error;
    }
  }

  /**
   * Upload file with progress tracking
   * ä¸Šä¼ æ–‡ä»¶å¹¶è·Ÿè¸ªè¿›åº¦
   */
  uploadWithProgress(formData, token, onProgress) {
    return new Promise((resolve, reject) => {
      const xhr = new XMLHttpRequest();

      console.log("[AudioTranscription] Starting upload to:", this.baseURL);

      // Track upload progress
      xhr.upload.addEventListener("progress", (e) => {
        if (e.lengthComputable) {
          // Upload progress: 10% - 50%
          const uploadProgress = Math.round((e.loaded / e.total) * 40) + 10;
          console.log(
            `[AudioTranscription] Upload progress: ${uploadProgress}% (${e.loaded}/${e.total} bytes)`,
          );
          if (onProgress) onProgress(uploadProgress);
        }
      });

      // Upload complete, waiting for server response
      xhr.upload.addEventListener("loadend", () => {
        console.log(
          "[AudioTranscription] Upload complete, waiting for server processing...",
        );
        if (onProgress) onProgress(55); // Show 55% to indicate upload done, processing started
      });

      // Track response progress (if available)
      xhr.addEventListener("progress", (e) => {
        if (e.lengthComputable) {
          // Response progress: 55% - 90%
          const responseProgress = Math.round((e.loaded / e.total) * 35) + 55;
          console.log(
            `[AudioTranscription] Response progress: ${responseProgress}%`,
          );
          if (onProgress) onProgress(responseProgress);
        } else {
          // If length not computable, show incremental progress
          console.log(
            "[AudioTranscription] Processing... (server response pending)",
          );
        }
      });

      // Handle completion
      xhr.addEventListener("load", () => {
        console.log(
          "[AudioTranscription] Request complete, status:",
          xhr.status,
        );

        if (xhr.status >= 200 && xhr.status < 300) {
          // Processing: 90%
          if (onProgress) onProgress(90);

          try {
            const result = JSON.parse(xhr.responseText);
            console.log("[AudioTranscription] Transcription successful");

            // Complete: 100%
            if (onProgress) onProgress(100);

            resolve(result);
          } catch (e) {
            console.error("[AudioTranscription] Parse error:", e);
            reject(new Error("è§£æå“åº”å¤±è´¥"));
          }
        } else {
          console.error(
            "[AudioTranscription] Request failed:",
            xhr.status,
            xhr.statusText,
          );
          try {
            const error = JSON.parse(xhr.responseText);
            reject(new Error(error.detail?.message || "è½¬å†™å¤±è´¥"));
          } catch (e) {
            reject(new Error(`è¯·æ±‚å¤±è´¥ (${xhr.status})`));
          }
        }
      });

      // Handle errors
      xhr.addEventListener("error", () => {
        console.error("[AudioTranscription] Network error");
        reject(new Error("ç½‘ç»œé”™è¯¯ï¼Œè¯·æ£€æŸ¥è¿æ¥"));
      });

      xhr.addEventListener("abort", () => {
        console.log("[AudioTranscription] Upload aborted");
        reject(new Error("ä¸Šä¼ å·²å–æ¶ˆ"));
      });

      xhr.addEventListener("timeout", () => {
        console.error("[AudioTranscription] Request timeout");
        reject(new Error("è¯·æ±‚è¶…æ—¶ï¼Œæ–‡ä»¶å¯èƒ½å¤ªå¤§æˆ–ç½‘ç»œå¤ªæ…¢"));
      });

      // Set timeout to 10 minutes (large files take time)
      xhr.timeout = 600000; // 10 minutes

      // Open and send request
      xhr.open("POST", this.baseURL);
      xhr.setRequestHeader("Authorization", `Bearer ${token}`);
      console.log("[AudioTranscription] Sending request...");
      xhr.send(formData);
    });
  }

  /**
   * Validate audio file before upload
   * ä¸Šä¼ å‰éªŒè¯éŸ³é¢‘æ–‡ä»¶
   */
  validateFile(file) {
    const errors = [];

    if (!file) {
      errors.push("è¯·é€‰æ‹©æ–‡ä»¶");
      return errors;
    }

    // Check file type
    const allowedExtensions = [
      ".mp3",
      ".mp4",
      ".mpeg",
      ".mpga",
      ".m4a",
      ".wav",
      ".webm",
    ];
    const fileExt = "." + file.name.split(".").pop().toLowerCase();

    if (!allowedExtensions.includes(fileExt)) {
      errors.push(`ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ã€‚æ”¯æŒ: ${allowedExtensions.join(", ")}`);
    }

    // Check file size
    const maxSize = 100 * 1024 * 1024; // 100MB
    if (file.size > maxSize) {
      errors.push(
        `æ–‡ä»¶å¤§å°è¶…è¿‡100MBé™åˆ¶ (å½“å‰: ${(file.size / 1024 / 1024).toFixed(2)}MB)`,
      );
    }

    if (file.size === 0) {
      errors.push("æ–‡ä»¶ä¸ºç©º");
    }

    return errors;
  }
}

// Export singleton instance
export default new AudioTranscriptionService();
